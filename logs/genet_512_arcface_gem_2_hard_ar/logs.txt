[09-17 13:10] - Parameters used for training: Namespace(arch='genet_normal', augmentation='hard', batch_size=64, config_file='configs/tmp/genet_gem2.yaml', criterion='arcface', criterion_params={'out_features': 3097, 's': 64.0, 'm': 0.8}, debug=False, ema_decay=0.0, embedding_size=512, model_params={}, name='genet_512_arcface_gem_2_hard_ar', optim='adamw', outdir='logs/genet_512_arcface_gem_2_hard_ar', phases=[{'ep': [0, 30], 'lr': [0.1, 0.001]}, {'ep': [31, 50], 'lr': [0.001, 1e-05]}], pooling='gem', resume='', root='data/interim', seed=42, size=512, tta=False, use_fp16=True, val_frequency=1, val_size=768, weight_decay=1e-05, workers=6)
[09-17 13:10] - Start training
[09-17 13:10] - Model size: 19.89M
[09-17 13:10] - Loss for this run is: AdditiveAngularMarginLoss(
  (criterion): CrossEntropyLoss()
)
[09-17 13:10] - Val size: 20643
[09-17 13:10] - Train size: 68811
[09-17 13:10] - True, None, None
[09-17 13:10] - Start phase #1 from epoch 0 to epoch 30: {'ep': [0, 30], 'lr': [0.1, 0.001], 'mom': [], 'mode': 'linear'}
[09-17 13:10] - Epoch 1 | lr 0.00e+00
[09-17 13:17] - 
TimeMeter profiling. Data time: 6.39E-04s. Model time: 3.88E-01s 

[09-17 13:21] - Train loss: 55.2083 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 13:21] - Val   loss: 54.9477 | Acc_@1: 0.0271 | mAP@10: 0.0416 | .5Acc+.5mAP: 0.0344 | CMC@10: 0.0922
[09-17 13:21] - Epoch  1: best loss improved from inf to 54.9477
[09-17 13:21] - Epoch 2 | lr 9.70e-02
[09-17 13:32] - Train loss: 54.7594 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 13:32] - Val   loss: 54.6869 | Acc_@1: 0.1054 | mAP@10: 0.1409 | .5Acc+.5mAP: 0.1232 | CMC@10: 0.2864
[09-17 13:32] - Epoch  2: best loss improved from 54.9477 to 54.6869
[09-17 13:32] - Epoch 3 | lr 9.37e-02
[09-17 13:43] - Train loss: 54.1587 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 13:43] - Val   loss: 54.0128 | Acc_@1: 0.3289 | mAP@10: 0.3619 | .5Acc+.5mAP: 0.3454 | CMC@10: 0.5843
[09-17 13:43] - Epoch  3: best loss improved from 54.6869 to 54.0128
[09-17 13:43] - Epoch 4 | lr 9.04e-02
[09-17 13:56] - Train loss: 53.1397 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 13:56] - Val   loss: 52.9882 | Acc_@1: 0.5127 | mAP@10: 0.5381 | .5Acc+.5mAP: 0.5254 | CMC@10: 0.7612
[09-17 13:56] - Epoch  4: best loss improved from 54.0128 to 52.9882
[09-17 13:56] - Epoch 5 | lr 8.71e-02
[09-17 14:09] - Train loss: 51.6809 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 14:09] - Val   loss: 52.0460 | Acc_@1: 0.6186 | mAP@10: 0.6215 | .5Acc+.5mAP: 0.6200 | CMC@10: 0.8104
[09-17 14:09] - Epoch  5: best loss improved from 52.9882 to 52.0460
[09-17 14:09] - Epoch 6 | lr 8.38e-02
[09-17 14:23] - Train loss: 49.8411 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 14:23] - Val   loss: 50.4032 | Acc_@1: 0.6865 | mAP@10: 0.6859 | .5Acc+.5mAP: 0.6862 | CMC@10: 0.8591
[09-17 14:23] - Epoch  6: best loss improved from 52.0460 to 50.4032
[09-17 14:23] - Epoch 7 | lr 8.05e-02
[09-17 14:36] - Train loss: 47.5691 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 14:36] - Val   loss: 49.2876 | Acc_@1: 0.7249 | mAP@10: 0.7200 | .5Acc+.5mAP: 0.7225 | CMC@10: 0.8778
[09-17 14:36] - Epoch  7: best loss improved from 50.4032 to 49.2876
[09-17 14:36] - Epoch 8 | lr 7.72e-02
[09-17 14:50] - Train loss: 44.9634 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 14:50] - Val   loss: 46.8475 | Acc_@1: 0.7715 | mAP@10: 0.7620 | .5Acc+.5mAP: 0.7667 | CMC@10: 0.8982
[09-17 14:50] - Epoch  8: best loss improved from 49.2876 to 46.8475
[09-17 14:50] - Epoch 9 | lr 7.39e-02
[09-17 15:03] - Train loss: 42.2372 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 15:03] - Val   loss: 44.9918 | Acc_@1: 0.8020 | mAP@10: 0.7915 | .5Acc+.5mAP: 0.7968 | CMC@10: 0.9169
[09-17 15:03] - Epoch  9: best loss improved from 46.8475 to 44.9918
[09-17 15:03] - Epoch 10 | lr 7.06e-02
[09-17 15:16] - Train loss: 39.6865 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 15:16] - Val   loss: 42.5273 | Acc_@1: 0.8075 | mAP@10: 0.7985 | .5Acc+.5mAP: 0.8030 | CMC@10: 0.9136
[09-17 15:16] - Epoch 10: best loss improved from 44.9918 to 42.5273
[09-17 15:16] - Epoch 11 | lr 6.73e-02
[09-17 15:28] - Train loss: 37.4200 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 15:28] - Val   loss: 40.4903 | Acc_@1: 0.8399 | mAP@10: 0.8313 | .5Acc+.5mAP: 0.8356 | CMC@10: 0.9349
[09-17 15:28] - Epoch 11: best loss improved from 42.5273 to 40.4903
[09-17 15:28] - Epoch 12 | lr 6.40e-02
[09-17 15:41] - Train loss: 35.1316 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 15:41] - Val   loss: 38.8656 | Acc_@1: 0.8577 | mAP@10: 0.8482 | .5Acc+.5mAP: 0.8529 | CMC@10: 0.9407
[09-17 15:41] - Epoch 12: best loss improved from 40.4903 to 38.8656
[09-17 15:41] - Epoch 13 | lr 6.07e-02
[09-17 15:53] - Train loss: 33.1091 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 15:53] - Val   loss: 37.6557 | Acc_@1: 0.8627 | mAP@10: 0.8536 | .5Acc+.5mAP: 0.8582 | CMC@10: 0.9477
[09-17 15:53] - Epoch 13: best loss improved from 38.8656 to 37.6557
[09-17 15:53] - Epoch 14 | lr 5.74e-02
[09-17 16:05] - Train loss: 31.1664 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 16:05] - Val   loss: 35.6841 | Acc_@1: 0.8757 | mAP@10: 0.8662 | .5Acc+.5mAP: 0.8709 | CMC@10: 0.9496
[09-17 16:05] - Epoch 14: best loss improved from 37.6557 to 35.6841
[09-17 16:05] - Epoch 15 | lr 5.41e-02
[09-17 16:18] - Train loss: 29.5034 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 16:18] - Val   loss: 34.3456 | Acc_@1: 0.8848 | mAP@10: 0.8765 | .5Acc+.5mAP: 0.8806 | CMC@10: 0.9585
[09-17 16:18] - Epoch 15: best loss improved from 35.6841 to 34.3456
[09-17 16:18] - Epoch 16 | lr 5.08e-02
[09-17 16:31] - Train loss: 27.8442 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 16:31] - Val   loss: 32.8855 | Acc_@1: 0.8886 | mAP@10: 0.8835 | .5Acc+.5mAP: 0.8861 | CMC@10: 0.9604
[09-17 16:31] - Epoch 16: best loss improved from 34.3456 to 32.8855
[09-17 16:31] - Epoch 17 | lr 4.75e-02
[09-17 16:45] - Train loss: 26.2090 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 16:45] - Val   loss: 31.7545 | Acc_@1: 0.8937 | mAP@10: 0.8912 | .5Acc+.5mAP: 0.8924 | CMC@10: 0.9618
[09-17 16:45] - Epoch 17: best loss improved from 32.8855 to 31.7545
[09-17 16:45] - Epoch 18 | lr 4.42e-02
[09-17 17:03] - Train loss: 24.7848 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 17:03] - Val   loss: 30.9191 | Acc_@1: 0.9069 | mAP@10: 0.8994 | .5Acc+.5mAP: 0.9032 | CMC@10: 0.9669
[09-17 17:03] - Epoch 18: best loss improved from 31.7545 to 30.9191
[09-17 17:03] - Epoch 19 | lr 4.09e-02
[09-17 17:18] - Train loss: 23.5835 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 17:18] - Val   loss: 29.2528 | Acc_@1: 0.9083 | mAP@10: 0.9034 | .5Acc+.5mAP: 0.9059 | CMC@10: 0.9666
[09-17 17:18] - Epoch 19: best loss improved from 30.9191 to 29.2528
[09-17 17:18] - Epoch 20 | lr 3.76e-02
[09-17 17:31] - Train loss: 22.3749 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 17:31] - Val   loss: 28.3168 | Acc_@1: 0.9155 | mAP@10: 0.9078 | .5Acc+.5mAP: 0.9117 | CMC@10: 0.9681
[09-17 17:31] - Epoch 20: best loss improved from 29.2528 to 28.3168
[09-17 17:31] - Epoch 21 | lr 3.43e-02
[09-17 17:46] - Train loss: 21.2803 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 17:46] - Val   loss: 27.8689 | Acc_@1: 0.9143 | mAP@10: 0.9097 | .5Acc+.5mAP: 0.9120 | CMC@10: 0.9681
[09-17 17:46] - Epoch 21: best loss improved from 28.3168 to 27.8689
[09-17 17:46] - Epoch 22 | lr 3.10e-02
[09-17 18:03] - Train loss: 20.3227 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 18:03] - Val   loss: 26.7573 | Acc_@1: 0.9229 | mAP@10: 0.9157 | .5Acc+.5mAP: 0.9193 | CMC@10: 0.9688
[09-17 18:03] - Epoch 22: best loss improved from 27.8689 to 26.7573
[09-17 18:04] - Epoch 23 | lr 2.77e-02
[09-17 18:18] - Train loss: 19.4713 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 18:18] - Val   loss: 25.7405 | Acc_@1: 0.9220 | mAP@10: 0.9179 | .5Acc+.5mAP: 0.9200 | CMC@10: 0.9700
[09-17 18:18] - Epoch 23: best loss improved from 26.7573 to 25.7405
[09-17 18:18] - Epoch 24 | lr 2.44e-02
[09-17 18:31] - Train loss: 18.6231 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 18:31] - Val   loss: 25.0888 | Acc_@1: 0.9253 | mAP@10: 0.9248 | .5Acc+.5mAP: 0.9251 | CMC@10: 0.9726
[09-17 18:31] - Epoch 24: best loss improved from 25.7405 to 25.0888
[09-17 18:31] - Epoch 25 | lr 2.11e-02
[09-17 18:44] - Train loss: 17.9443 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 18:44] - Val   loss: 24.3472 | Acc_@1: 0.9311 | mAP@10: 0.9268 | .5Acc+.5mAP: 0.9290 | CMC@10: 0.9741
[09-17 18:44] - Epoch 25: best loss improved from 25.0888 to 24.3472
[09-17 18:44] - Epoch 26 | lr 1.78e-02
[09-17 18:57] - Train loss: 17.2594 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 18:57] - Val   loss: 23.6953 | Acc_@1: 0.9366 | mAP@10: 0.9294 | .5Acc+.5mAP: 0.9330 | CMC@10: 0.9731
[09-17 18:57] - Epoch 26: best loss improved from 24.3472 to 23.6953
[09-17 18:57] - Epoch 27 | lr 1.45e-02
[09-17 19:10] - Train loss: 16.7255 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 19:10] - Val   loss: 23.2357 | Acc_@1: 0.9354 | mAP@10: 0.9315 | .5Acc+.5mAP: 0.9334 | CMC@10: 0.9760
[09-17 19:10] - Epoch 27: best loss improved from 23.6953 to 23.2357
[09-17 19:10] - Epoch 28 | lr 1.12e-02
[09-17 19:24] - Train loss: 16.2060 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 19:24] - Val   loss: 22.9330 | Acc_@1: 0.9325 | mAP@10: 0.9310 | .5Acc+.5mAP: 0.9318 | CMC@10: 0.9753
[09-17 19:24] - Epoch 28: best loss improved from 23.2357 to 22.9330
[09-17 19:24] - Epoch 29 | lr 7.90e-03
[09-17 19:36] - Train loss: 15.8807 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 19:36] - Val   loss: 22.6951 | Acc_@1: 0.9345 | mAP@10: 0.9325 | .5Acc+.5mAP: 0.9335 | CMC@10: 0.9746
[09-17 19:36] - Epoch 29: best loss improved from 22.9330 to 22.6951
[09-17 19:36] - Epoch 30 | lr 4.60e-03
[09-17 19:48] - Train loss: 15.5665 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 19:48] - Val   loss: 22.3918 | Acc_@1: 0.9345 | mAP@10: 0.9335 | .5Acc+.5mAP: 0.9340 | CMC@10: 0.9774
[09-17 19:48] - Epoch 30: best loss improved from 22.6951 to 22.3918
[09-17 19:48] - Loading best model from previous phase
[09-17 19:48] - Start phase #2 from epoch 31 to epoch 50: {'ep': [31, 50], 'lr': [0.001, 1e-05], 'mom': [], 'mode': 'linear'}
[09-17 19:48] - Loading best model from previous phase
[09-17 19:48] - Finished Training. Took: 398.17m
