[09-20 05:17] - Parameters used for training: Namespace(arch='genet_small', augmentation='hard', batch_size=96, config_file='configs/2_genet_small_512_finetune.yaml', criterion='arcface', criterion_params={'out_features': 3097, 's': 80.0, 'm': 20.0}, debug=False, ema_decay=0.0, embedding_size=512, freeze_bn=False, model_params={}, name='genet_small_512_hard_arcface80_20', optim='adamw', outdir='logs/genet_small_512_hard_arcface80_20', phases=[{'ep': [0, 1], 'lr': [1e-06, 0.001]}, {'ep': [1, 30], 'lr': [0.001, 1e-05]}], pooling='gem', resume='logs/genet_small_512_light_arcface80_20/model.chpn', root='data/interim', seed=42, size=512, tta=False, use_fp16=True, val_frequency=1, val_size=768, weight_decay=1e-05, workers=8)
[09-20 05:17] - Model size: 7.24M
[09-20 05:17] - Loss for this run is: AdditiveAngularMarginLoss(
  (criterion): CrossEntropyLoss()
)
[09-20 05:17] - Using sizes {(680, 512), (512, 512), (1024, 512), (512, 904), (512, 640), (640, 512), (512, 768), (904, 512), (512, 680), (512, 1024), (768, 512)} for train
[09-20 05:17] - Using sizes {(768, 1360), (960, 768), (1536, 768), (768, 768), (1360, 768), (1152, 768), (768, 1536), (1024, 768), (768, 960), (768, 1024), (768, 1152)} for validation
[09-20 05:17] - Val size: 16672
[09-20 05:17] - Train size: 51935
[09-20 05:17] - Start training
[09-20 05:17] - Start phase #1 from epoch 0 to epoch 1: {'ep': [0, 1], 'lr': [1e-06, 0.001], 'mom': [], 'mode': 'linear'}
[09-20 05:17] - Epoch 1 | lr 0.00e+00
[09-20 05:24] - TimeMeter profiling. Data time: 2.82E-01s. Model time: 6.83E-01s 

[09-20 05:27] - Train loss: 72.2604 | Acc@1: 0.0000 | mAP@10: 0.0000 | target: 0.0000 | mAP@R: 0.0000
[09-20 05:27] - Val   loss: 86.7090 | Acc@1: 0.7729 | mAP@10: 0.7567 | target: 0.7648 | mAP@R: 0.7141
[09-20 05:27] - Epoch  1: best target improved from -inf to 0.7648
[09-20 05:27] - Epoch  1: best mAP@R improved from -inf to 0.7141
[09-20 05:27] - Loading best model from previous phase
[09-20 05:27] - Start phase #2 from epoch 1 to epoch 30: {'ep': [1, 30], 'lr': [0.001, 1e-05], 'mom': [], 'mode': 'linear'}
[09-20 05:27] - Epoch 2 | lr 8.38e-04
[09-20 05:38] - Train loss: 70.3275 | Acc@1: 0.0000 | mAP@10: 0.0000 | target: 0.0000 | mAP@R: 0.0000
[09-20 05:38] - Val   loss: 86.7410 | Acc@1: 0.7852 | mAP@10: 0.7688 | target: 0.7770 | mAP@R: 0.7217
[09-20 05:38] - Epoch  2: best target improved from 0.7648 to 0.7770
[09-20 05:38] - Epoch  2: best mAP@R improved from 0.7141 to 0.7217
[09-20 05:38] - Epoch 3 | lr 9.71e-04
[09-20 05:49] - Train loss: 69.0893 | Acc@1: 0.0000 | mAP@10: 0.0000 | target: 0.0000 | mAP@R: 0.0000
[09-20 05:49] - Val   loss: 87.4983 | Acc@1: 0.7949 | mAP@10: 0.7683 | target: 0.7816 | mAP@R: 0.7250
[09-20 05:49] - Epoch  3: best target improved from 0.7770 to 0.7816
[09-20 05:49] - Epoch  3: best mAP@R improved from 0.7217 to 0.7250
[09-20 05:49] - Epoch 4 | lr 9.37e-04
