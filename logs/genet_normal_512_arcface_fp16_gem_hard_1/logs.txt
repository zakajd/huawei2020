[09-16 19:09] - Parameters used for training: Namespace(arch='genet_normal', augmentation='hard', batch_size=96, config_file='configs/genet_normal.yaml', criterion='arcface', criterion_params={'out_features': 3097, 's': 64.0, 'm': 0.5}, debug=False, ema_decay=0.0, embedding_size=512, model_params={}, name='genet_normal_512_arcface_fp16_gem_hard', optim='adamw', outdir='logs/genet_normal_512_arcface_fp16_gem_hard_1', phases=[{'ep': [0, 50], 'lr': [0.1, 1e-05], 'mode': 'cos'}], pooling='gem', resume='', root='data/interim', seed=42, size=512, tta=False, use_fp16=True, val_frequency=1, val_size=768, weight_decay=1e-05, workers=6)
[09-16 19:09] - Start training
[09-16 19:09] - Model size: 19.89M
[09-16 19:09] - Loss for this run is: AdditiveAngularMarginLoss(
  (criterion): CrossEntropyLoss()
)
[09-16 19:09] - Val size: 20643
[09-16 19:09] - Train size: 68811
[09-16 19:09] - Start phase #1 from epoch 0 to epoch 50: {'ep': [0, 50], 'lr': [0.1, 1e-05], 'mode': 'cos', 'mom': []}
[09-16 19:09] - Epoch 1 | lr 0.00e+00
[09-16 19:14] - 
TimeMeter profiling. Data time: 8.88E-04s. Model time: 4.09E-01s 

[09-16 19:26] - Train loss: 39.8573 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:26] - Val   loss: 39.3778 | Acc_@1: 0.1171 | mAP@10: 0.1505 | .5Acc+.5mAP: 0.1338 | CMC@10: 0.3017
[09-16 19:26] - Epoch  1: best loss improved from inf to 39.3778
[09-16 19:26] - Epoch 2 | lr 9.99e-02
[09-16 19:33] - Train loss: 38.0381 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:33] - Val   loss: 37.6355 | Acc_@1: 0.4630 | mAP@10: 0.4875 | .5Acc+.5mAP: 0.4752 | CMC@10: 0.7086
[09-16 19:33] - Epoch  2: best loss improved from 39.3778 to 37.6355
[09-16 19:33] - Epoch 3 | lr 9.96e-02
[09-16 19:41] - Train loss: 35.0648 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:41] - Val   loss: 35.8862 | Acc_@1: 0.5948 | mAP@10: 0.6123 | .5Acc+.5mAP: 0.6035 | CMC@10: 0.8140
[09-16 19:41] - Epoch  3: best loss improved from 37.6355 to 35.8862
[09-16 19:41] - Epoch 4 | lr 9.92e-02
[09-16 19:48] - Train loss: 31.6050 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:48] - Val   loss: 33.3910 | Acc_@1: 0.6935 | mAP@10: 0.6918 | .5Acc+.5mAP: 0.6926 | CMC@10: 0.8651
[09-16 19:48] - Epoch  4: best loss improved from 35.8862 to 33.3910
[09-16 19:48] - Epoch 5 | lr 9.85e-02
[09-16 19:56] - Train loss: 28.0074 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:56] - Val   loss: 31.1477 | Acc_@1: 0.7381 | mAP@10: 0.7358 | .5Acc+.5mAP: 0.7370 | CMC@10: 0.8937
[09-16 19:56] - Epoch  5: best loss improved from 33.3910 to 31.1477
[09-16 19:56] - Epoch 6 | lr 9.76e-02
[09-16 20:03] - Train loss: 24.4584 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:03] - Val   loss: 27.2425 | Acc_@1: 0.8164 | mAP@10: 0.8143 | .5Acc+.5mAP: 0.8153 | CMC@10: 0.9330
[09-16 20:03] - Epoch  6: best loss improved from 31.1477 to 27.2425
[09-16 20:03] - Epoch 7 | lr 9.66e-02
[09-16 20:11] - Train loss: 21.2054 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:11] - Val   loss: 25.7033 | Acc_@1: 0.8272 | mAP@10: 0.8202 | .5Acc+.5mAP: 0.8237 | CMC@10: 0.9299
[09-16 20:11] - Epoch  7: best loss improved from 27.2425 to 25.7033
[09-16 20:11] - Epoch 8 | lr 9.53e-02
[09-16 20:18] - Train loss: 18.3136 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:18] - Val   loss: 23.1446 | Acc_@1: 0.8557 | mAP@10: 0.8514 | .5Acc+.5mAP: 0.8536 | CMC@10: 0.9450
[09-16 20:18] - Epoch  8: best loss improved from 25.7033 to 23.1446
[09-16 20:18] - Epoch 9 | lr 9.39e-02
[09-16 20:26] - Train loss: 15.8228 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:26] - Val   loss: 20.5537 | Acc_@1: 0.8901 | mAP@10: 0.8806 | .5Acc+.5mAP: 0.8853 | CMC@10: 0.9582
[09-16 20:26] - Epoch  9: best loss improved from 23.1446 to 20.5537
[09-16 20:26] - Epoch 10 | lr 9.23e-02
[09-16 20:33] - Train loss: 13.6512 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:33] - Val   loss: 18.3927 | Acc_@1: 0.9078 | mAP@10: 0.9009 | .5Acc+.5mAP: 0.9044 | CMC@10: 0.9690
[09-16 20:33] - Epoch 10: best loss improved from 20.5537 to 18.3927
[09-16 20:33] - Epoch 11 | lr 9.06e-02
[09-16 20:41] - Train loss: 11.8100 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:41] - Val   loss: 16.7546 | Acc_@1: 0.9119 | mAP@10: 0.9064 | .5Acc+.5mAP: 0.9091 | CMC@10: 0.9693
[09-16 20:41] - Epoch 11: best loss improved from 18.3927 to 16.7546
[09-16 20:41] - Epoch 12 | lr 8.87e-02
[09-16 20:48] - Train loss: 10.3686 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:48] - Val   loss: 15.8570 | Acc_@1: 0.9145 | mAP@10: 0.9105 | .5Acc+.5mAP: 0.9125 | CMC@10: 0.9712
[09-16 20:48] - Epoch 12: best loss improved from 16.7546 to 15.8570
[09-16 20:48] - Epoch 13 | lr 8.66e-02
[09-16 20:56] - Train loss: 9.0891 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:56] - Val   loss: 14.6370 | Acc_@1: 0.9155 | mAP@10: 0.9149 | .5Acc+.5mAP: 0.9152 | CMC@10: 0.9714
[09-16 20:56] - Epoch 13: best loss improved from 15.8570 to 14.6370
[09-16 20:56] - Epoch 14 | lr 8.44e-02
[09-16 21:03] - Train loss: 8.0566 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:03] - Val   loss: 13.6895 | Acc_@1: 0.9277 | mAP@10: 0.9277 | .5Acc+.5mAP: 0.9277 | CMC@10: 0.9796
[09-16 21:03] - Epoch 14: best loss improved from 14.6370 to 13.6895
[09-16 21:03] - Epoch 15 | lr 8.21e-02
[09-16 21:11] - Train loss: 7.1812 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:11] - Val   loss: 12.7128 | Acc_@1: 0.9369 | mAP@10: 0.9338 | .5Acc+.5mAP: 0.9353 | CMC@10: 0.9801
[09-16 21:11] - Epoch 15: best loss improved from 13.6895 to 12.7128
[09-16 21:11] - Epoch 16 | lr 7.96e-02
[09-16 21:18] - Train loss: 6.4350 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:18] - Val   loss: 12.6661 | Acc_@1: 0.9381 | mAP@10: 0.9369 | .5Acc+.5mAP: 0.9375 | CMC@10: 0.9820
[09-16 21:18] - Epoch 16: best loss improved from 12.7128 to 12.6661
[09-16 21:18] - Epoch 17 | lr 7.70e-02
[09-16 21:26] - Train loss: 5.7725 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:26] - Val   loss: 11.3894 | Acc_@1: 0.9422 | mAP@10: 0.9401 | .5Acc+.5mAP: 0.9411 | CMC@10: 0.9830
[09-16 21:26] - Epoch 17: best loss improved from 12.6661 to 11.3894
[09-16 21:26] - Epoch 18 | lr 7.43e-02
[09-16 21:33] - Train loss: 5.2022 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:33] - Val   loss: 10.7772 | Acc_@1: 0.9503 | mAP@10: 0.9498 | .5Acc+.5mAP: 0.9500 | CMC@10: 0.9844
[09-16 21:33] - Epoch 18: best loss improved from 11.3894 to 10.7772
[09-16 21:33] - Epoch 19 | lr 7.15e-02
[09-16 21:41] - Train loss: 4.7326 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:41] - Val   loss: 10.5679 | Acc_@1: 0.9515 | mAP@10: 0.9497 | .5Acc+.5mAP: 0.9506 | CMC@10: 0.9851
[09-16 21:41] - Epoch 19: best loss improved from 10.7772 to 10.5679
[09-16 21:41] - Epoch 20 | lr 6.86e-02
[09-16 21:48] - Train loss: 4.3350 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:48] - Val   loss: 10.3680 | Acc_@1: 0.9503 | mAP@10: 0.9497 | .5Acc+.5mAP: 0.9500 | CMC@10: 0.9844
[09-16 21:48] - Epoch 20: best loss improved from 10.5679 to 10.3680
[09-16 21:48] - Epoch 21 | lr 6.57e-02
[09-16 21:56] - Train loss: 3.9351 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:56] - Val   loss: 10.1221 | Acc_@1: 0.9534 | mAP@10: 0.9529 | .5Acc+.5mAP: 0.9532 | CMC@10: 0.9882
[09-16 21:56] - Epoch 21: best loss improved from 10.3680 to 10.1221
[09-16 21:56] - Epoch 22 | lr 6.27e-02
[09-16 22:03] - Train loss: 3.5985 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:03] - Val   loss: 9.5497 | Acc_@1: 0.9566 | mAP@10: 0.9573 | .5Acc+.5mAP: 0.9570 | CMC@10: 0.9873
[09-16 22:03] - Epoch 22: best loss improved from 10.1221 to 9.5497
[09-16 22:03] - Epoch 23 | lr 5.96e-02
[09-16 22:11] - Train loss: 3.3039 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:11] - Val   loss: 9.3813 | Acc_@1: 0.9592 | mAP@10: 0.9574 | .5Acc+.5mAP: 0.9583 | CMC@10: 0.9863
[09-16 22:11] - Epoch 23: best loss improved from 9.5497 to 9.3813
[09-16 22:11] - Epoch 24 | lr 5.65e-02
[09-16 22:18] - Train loss: 3.0785 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:18] - Val   loss: 9.0247 | Acc_@1: 0.9573 | mAP@10: 0.9576 | .5Acc+.5mAP: 0.9575 | CMC@10: 0.9875
[09-16 22:18] - Epoch 24: best loss improved from 9.3813 to 9.0247
[09-16 22:18] - Epoch 25 | lr 5.34e-02
[09-16 22:26] - Train loss: 2.8503 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:26] - Val   loss: 8.7177 | Acc_@1: 0.9604 | mAP@10: 0.9602 | .5Acc+.5mAP: 0.9603 | CMC@10: 0.9875
[09-16 22:26] - Epoch 25: best loss improved from 9.0247 to 8.7177
[09-16 22:26] - Epoch 26 | lr 5.02e-02
[09-16 22:33] - Train loss: 2.6399 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:33] - Val   loss: 8.2941 | Acc_@1: 0.9647 | mAP@10: 0.9640 | .5Acc+.5mAP: 0.9644 | CMC@10: 0.9887
[09-16 22:33] - Epoch 26: best loss improved from 8.7177 to 8.2941
[09-16 22:33] - Epoch 27 | lr 4.71e-02
[09-16 22:41] - Train loss: 2.4564 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:41] - Val   loss: 8.4197 | Acc_@1: 0.9623 | mAP@10: 0.9617 | .5Acc+.5mAP: 0.9620 | CMC@10: 0.9887
[09-16 22:41] - Epoch 28 | lr 4.40e-02
[09-16 22:48] - Train loss: 2.3055 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:48] - Val   loss: 8.5200 | Acc_@1: 0.9635 | mAP@10: 0.9633 | .5Acc+.5mAP: 0.9634 | CMC@10: 0.9892
[09-16 22:48] - Epoch 29 | lr 4.09e-02
[09-16 22:56] - Train loss: 2.1746 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:56] - Val   loss: 7.7738 | Acc_@1: 0.9669 | mAP@10: 0.9669 | .5Acc+.5mAP: 0.9669 | CMC@10: 0.9906
[09-16 22:56] - Epoch 29: best loss improved from 8.2941 to 7.7738
[09-16 22:56] - Epoch 30 | lr 3.78e-02
[09-16 23:03] - Train loss: 2.0254 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:03] - Val   loss: 7.6175 | Acc_@1: 0.9654 | mAP@10: 0.9659 | .5Acc+.5mAP: 0.9657 | CMC@10: 0.9894
[09-16 23:03] - Epoch 30: best loss improved from 7.7738 to 7.6175
[09-16 23:03] - Epoch 31 | lr 3.48e-02
[09-16 23:11] - Train loss: 1.9163 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:11] - Val   loss: 7.4056 | Acc_@1: 0.9702 | mAP@10: 0.9702 | .5Acc+.5mAP: 0.9702 | CMC@10: 0.9909
[09-16 23:11] - Epoch 31: best loss improved from 7.6175 to 7.4056
[09-16 23:11] - Epoch 32 | lr 3.18e-02
[09-16 23:18] - Train loss: 1.8309 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:18] - Val   loss: 7.5500 | Acc_@1: 0.9666 | mAP@10: 0.9680 | .5Acc+.5mAP: 0.9673 | CMC@10: 0.9902
[09-16 23:18] - Epoch 33 | lr 2.89e-02
[09-16 23:26] - Train loss: 1.7499 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:26] - Val   loss: 7.2622 | Acc_@1: 0.9688 | mAP@10: 0.9695 | .5Acc+.5mAP: 0.9691 | CMC@10: 0.9897
[09-16 23:26] - Epoch 33: best loss improved from 7.4056 to 7.2622
[09-16 23:26] - Epoch 34 | lr 2.61e-02
[09-16 23:33] - Train loss: 1.6678 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:33] - Val   loss: 7.0915 | Acc_@1: 0.9683 | mAP@10: 0.9711 | .5Acc+.5mAP: 0.9697 | CMC@10: 0.9911
[09-16 23:33] - Epoch 34: best loss improved from 7.2622 to 7.0915
[09-16 23:33] - Epoch 35 | lr 2.34e-02
[09-16 23:41] - Train loss: 1.5951 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:41] - Val   loss: 7.0117 | Acc_@1: 0.9726 | mAP@10: 0.9723 | .5Acc+.5mAP: 0.9725 | CMC@10: 0.9918
[09-16 23:41] - Epoch 35: best loss improved from 7.0915 to 7.0117
[09-16 23:41] - Epoch 36 | lr 2.08e-02
[09-16 23:48] - Train loss: 1.5456 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:48] - Val   loss: 6.9069 | Acc_@1: 0.9710 | mAP@10: 0.9725 | .5Acc+.5mAP: 0.9717 | CMC@10: 0.9930
[09-16 23:48] - Epoch 36: best loss improved from 7.0117 to 6.9069
[09-16 23:48] - Epoch 37 | lr 1.83e-02
[09-16 23:56] - Train loss: 1.4987 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 23:56] - Val   loss: 6.8406 | Acc_@1: 0.9722 | mAP@10: 0.9728 | .5Acc+.5mAP: 0.9725 | CMC@10: 0.9928
[09-16 23:56] - Epoch 37: best loss improved from 6.9069 to 6.8406
[09-16 23:56] - Epoch 38 | lr 1.60e-02
[09-17 00:03] - Train loss: 1.4548 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:03] - Val   loss: 6.8675 | Acc_@1: 0.9722 | mAP@10: 0.9734 | .5Acc+.5mAP: 0.9728 | CMC@10: 0.9926
[09-17 00:03] - Epoch 39 | lr 1.37e-02
[09-17 00:11] - Train loss: 1.4281 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:11] - Val   loss: 6.7364 | Acc_@1: 0.9731 | mAP@10: 0.9736 | .5Acc+.5mAP: 0.9734 | CMC@10: 0.9923
[09-17 00:11] - Epoch 39: best loss improved from 6.8406 to 6.7364
[09-17 00:11] - Epoch 40 | lr 1.16e-02
[09-17 00:19] - Train loss: 1.4080 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:19] - Val   loss: 6.6712 | Acc_@1: 0.9748 | mAP@10: 0.9747 | .5Acc+.5mAP: 0.9747 | CMC@10: 0.9928
[09-17 00:19] - Epoch 40: best loss improved from 6.7364 to 6.6712
[09-17 00:19] - Epoch 41 | lr 9.70e-03
[09-17 00:26] - Train loss: 1.3731 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:26] - Val   loss: 6.7221 | Acc_@1: 0.9724 | mAP@10: 0.9733 | .5Acc+.5mAP: 0.9728 | CMC@10: 0.9921
[09-17 00:26] - Epoch 42 | lr 7.92e-03
[09-17 00:34] - Train loss: 1.3610 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:34] - Val   loss: 6.5317 | Acc_@1: 0.9724 | mAP@10: 0.9735 | .5Acc+.5mAP: 0.9730 | CMC@10: 0.9923
[09-17 00:34] - Epoch 42: best loss improved from 6.6712 to 6.5317
[09-17 00:34] - Epoch 43 | lr 6.31e-03
[09-17 00:41] - Train loss: 1.3375 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:41] - Val   loss: 6.5994 | Acc_@1: 0.9724 | mAP@10: 0.9732 | .5Acc+.5mAP: 0.9728 | CMC@10: 0.9923
[09-17 00:41] - Epoch 44 | lr 4.87e-03
[09-17 00:49] - Train loss: 1.3140 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:49] - Val   loss: 6.4516 | Acc_@1: 0.9743 | mAP@10: 0.9743 | .5Acc+.5mAP: 0.9743 | CMC@10: 0.9928
[09-17 00:49] - Epoch 44: best loss improved from 6.5317 to 6.4516
[09-17 00:49] - Epoch 45 | lr 3.61e-03
[09-17 00:57] - Train loss: 1.3104 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 00:57] - Val   loss: 6.5311 | Acc_@1: 0.9729 | mAP@10: 0.9735 | .5Acc+.5mAP: 0.9732 | CMC@10: 0.9923
[09-17 00:57] - Epoch 46 | lr 2.53e-03
[09-17 01:05] - Train loss: 1.3024 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 01:05] - Val   loss: 6.4778 | Acc_@1: 0.9726 | mAP@10: 0.9739 | .5Acc+.5mAP: 0.9733 | CMC@10: 0.9930
[09-17 01:05] - Epoch 47 | lr 1.64e-03
[09-17 01:12] - Train loss: 1.2997 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 01:12] - Val   loss: 6.4941 | Acc_@1: 0.9734 | mAP@10: 0.9735 | .5Acc+.5mAP: 0.9735 | CMC@10: 0.9926
[09-17 01:12] - Epoch 48 | lr 9.40e-04
[09-17 01:20] - Train loss: 1.2765 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 01:20] - Val   loss: 6.5206 | Acc_@1: 0.9719 | mAP@10: 0.9731 | .5Acc+.5mAP: 0.9725 | CMC@10: 0.9921
[09-17 01:20] - Epoch 49 | lr 4.34e-04
[09-17 01:27] - Train loss: 1.2682 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 01:27] - Val   loss: 6.4557 | Acc_@1: 0.9736 | mAP@10: 0.9741 | .5Acc+.5mAP: 0.9739 | CMC@10: 0.9926
[09-17 01:27] - Epoch 50 | lr 1.24e-04
[09-17 01:35] - Train loss: 1.2772 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-17 01:35] - Val   loss: 6.4365 | Acc_@1: 0.9731 | mAP@10: 0.9741 | .5Acc+.5mAP: 0.9736 | CMC@10: 0.9926
[09-17 01:35] - Epoch 50: best loss improved from 6.4516 to 6.4365
[09-17 01:35] - Loading best model from previous phase
[09-17 01:35] - Finished Training. Took: 385.67m
