[09-16 17:33] - Parameters used for training: Namespace(arch='genet_normal', augmentation='light', batch_size=96, config_file='configs/genet_normal.yaml', criterion='arcface', criterion_params={'out_features': 3097, 's': 64.0, 'm': 0.5}, debug=False, ema_decay=0.0, embedding_size=512, model_params={}, name='genet_normal_512_arcface_fp16_gem_light', optim='adamw', outdir='logs/genet_normal_512_arcface_fp16_gem_light', phases=[{'ep': [0, 50], 'lr': [0.05, 1e-05], 'mode': 'cos'}], pooling='gem', resume='', root='data/interim', seed=42, size=512, tta=False, use_fp16=True, val_frequency=1, val_size=768, weight_decay=1e-05, workers=6)
[09-16 17:33] - Start training
[09-16 17:33] - Model size: 19.89M
[09-16 17:33] - Loss for this run is: AdditiveAngularMarginLoss(
  (criterion): CrossEntropyLoss()
)
[09-16 17:33] - Val size: 20641
[09-16 17:33] - Train size: 68805
[09-16 17:33] - Start phase #1 from epoch 0 to epoch 50: {'ep': [0, 50], 'lr': [0.05, 1e-05], 'mode': 'cos', 'mom': []}
[09-16 17:34] - Epoch 1 | lr 0.00e+00
[09-16 17:39] - 
TimeMeter profiling. Data time: 8.19E-04s. Model time: 4.29E-01s 

[09-16 17:41] - Train loss: 38.7180 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 17:41] - Val   loss: 36.9962 | Acc_@1: 0.5609 | mAP@10: 0.5814 | .5Acc+.5mAP: 0.5711 | CMC@10: 0.7946
[09-16 17:41] - Epoch  1: best loss improved from inf to 36.9962
[09-16 17:41] - Epoch 2 | lr 5.00e-02
[09-16 17:49] - Train loss: 33.4835 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 17:49] - Val   loss: 33.9473 | Acc_@1: 0.7120 | mAP@10: 0.7133 | .5Acc+.5mAP: 0.7127 | CMC@10: 0.8770
[09-16 17:49] - Epoch  2: best loss improved from 36.9962 to 33.9473
[09-16 17:49] - Epoch 3 | lr 4.98e-02
[09-16 17:57] - Train loss: 28.3032 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 17:57] - Val   loss: 30.4507 | Acc_@1: 0.7740 | mAP@10: 0.7687 | .5Acc+.5mAP: 0.7713 | CMC@10: 0.9082
[09-16 17:57] - Epoch  3: best loss improved from 33.9473 to 30.4507
[09-16 17:57] - Epoch 4 | lr 4.96e-02
[09-16 18:04] - Train loss: 23.8399 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:04] - Val   loss: 26.8715 | Acc_@1: 0.8458 | mAP@10: 0.8373 | .5Acc+.5mAP: 0.8415 | CMC@10: 0.9460
[09-16 18:04] - Epoch  4: best loss improved from 30.4507 to 26.8715
[09-16 18:04] - Epoch 5 | lr 4.92e-02
[09-16 18:12] - Train loss: 20.1069 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:12] - Val   loss: 23.4433 | Acc_@1: 0.8609 | mAP@10: 0.8569 | .5Acc+.5mAP: 0.8589 | CMC@10: 0.9534
[09-16 18:12] - Epoch  5: best loss improved from 26.8715 to 23.4433
[09-16 18:12] - Epoch 6 | lr 4.88e-02
[09-16 18:20] - Train loss: 16.9665 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:20] - Val   loss: 19.3300 | Acc_@1: 0.8912 | mAP@10: 0.8846 | .5Acc+.5mAP: 0.8879 | CMC@10: 0.9608
[09-16 18:20] - Epoch  6: best loss improved from 23.4433 to 19.3300
[09-16 18:20] - Epoch 7 | lr 4.83e-02
[09-16 18:28] - Train loss: 14.3989 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:28] - Val   loss: 17.5479 | Acc_@1: 0.9102 | mAP@10: 0.9017 | .5Acc+.5mAP: 0.9059 | CMC@10: 0.9719
[09-16 18:28] - Epoch  7: best loss improved from 19.3300 to 17.5479
[09-16 18:28] - Epoch 8 | lr 4.77e-02
[09-16 18:35] - Train loss: 12.4745 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:35] - Val   loss: 16.8177 | Acc_@1: 0.9130 | mAP@10: 0.9116 | .5Acc+.5mAP: 0.9123 | CMC@10: 0.9772
[09-16 18:35] - Epoch  8: best loss improved from 17.5479 to 16.8177
[09-16 18:35] - Epoch 9 | lr 4.70e-02
[09-16 18:43] - Train loss: 10.8226 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:43] - Val   loss: 15.8458 | Acc_@1: 0.9183 | mAP@10: 0.9136 | .5Acc+.5mAP: 0.9160 | CMC@10: 0.9719
[09-16 18:43] - Epoch  9: best loss improved from 16.8177 to 15.8458
[09-16 18:43] - Epoch 10 | lr 4.62e-02
[09-16 18:51] - Train loss: 9.6295 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:51] - Val   loss: 14.3989 | Acc_@1: 0.9260 | mAP@10: 0.9253 | .5Acc+.5mAP: 0.9256 | CMC@10: 0.9798
[09-16 18:51] - Epoch 10: best loss improved from 15.8458 to 14.3989
[09-16 18:51] - Epoch 11 | lr 4.53e-02
[09-16 18:58] - Train loss: 8.5328 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 18:58] - Val   loss: 12.8982 | Acc_@1: 0.9332 | mAP@10: 0.9295 | .5Acc+.5mAP: 0.9314 | CMC@10: 0.9762
[09-16 18:58] - Epoch 11: best loss improved from 14.3989 to 12.8982
[09-16 18:58] - Epoch 12 | lr 4.43e-02
[09-16 19:06] - Train loss: 7.6141 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:06] - Val   loss: 13.1642 | Acc_@1: 0.9347 | mAP@10: 0.9324 | .5Acc+.5mAP: 0.9335 | CMC@10: 0.9777
[09-16 19:06] - Epoch 13 | lr 4.33e-02
[09-16 19:14] - Train loss: 6.9310 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:14] - Val   loss: 11.4881 | Acc_@1: 0.9467 | mAP@10: 0.9456 | .5Acc+.5mAP: 0.9461 | CMC@10: 0.9837
[09-16 19:14] - Epoch 13: best loss improved from 12.8982 to 11.4881
[09-16 19:14] - Epoch 14 | lr 4.22e-02
[09-16 19:21] - Train loss: 6.2593 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:21] - Val   loss: 11.6682 | Acc_@1: 0.9472 | mAP@10: 0.9460 | .5Acc+.5mAP: 0.9466 | CMC@10: 0.9856
[09-16 19:21] - Epoch 15 | lr 4.10e-02
[09-16 19:29] - Train loss: 5.5863 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:29] - Val   loss: 11.0510 | Acc_@1: 0.9500 | mAP@10: 0.9489 | .5Acc+.5mAP: 0.9495 | CMC@10: 0.9873
[09-16 19:29] - Epoch 15: best loss improved from 11.4881 to 11.0510
[09-16 19:29] - Epoch 16 | lr 3.98e-02
[09-16 19:36] - Train loss: 5.1590 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:36] - Val   loss: 9.9830 | Acc_@1: 0.9584 | mAP@10: 0.9553 | .5Acc+.5mAP: 0.9569 | CMC@10: 0.9880
[09-16 19:36] - Epoch 16: best loss improved from 11.0510 to 9.9830
[09-16 19:36] - Epoch 17 | lr 3.85e-02
[09-16 19:44] - Train loss: 4.6266 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:44] - Val   loss: 10.0375 | Acc_@1: 0.9556 | mAP@10: 0.9540 | .5Acc+.5mAP: 0.9548 | CMC@10: 0.9868
[09-16 19:44] - Epoch 18 | lr 3.71e-02
[09-16 19:52] - Train loss: 4.3288 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:52] - Val   loss: 9.6018 | Acc_@1: 0.9575 | mAP@10: 0.9569 | .5Acc+.5mAP: 0.9572 | CMC@10: 0.9890
[09-16 19:52] - Epoch 18: best loss improved from 9.9830 to 9.6018
[09-16 19:52] - Epoch 19 | lr 3.58e-02
[09-16 19:59] - Train loss: 3.9103 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 19:59] - Val   loss: 9.5172 | Acc_@1: 0.9589 | mAP@10: 0.9582 | .5Acc+.5mAP: 0.9586 | CMC@10: 0.9892
[09-16 19:59] - Epoch 19: best loss improved from 9.6018 to 9.5172
[09-16 19:59] - Epoch 20 | lr 3.43e-02
[09-16 20:07] - Train loss: 3.5937 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:07] - Val   loss: 9.1513 | Acc_@1: 0.9589 | mAP@10: 0.9592 | .5Acc+.5mAP: 0.9591 | CMC@10: 0.9875
[09-16 20:07] - Epoch 20: best loss improved from 9.5172 to 9.1513
[09-16 20:07] - Epoch 21 | lr 3.28e-02
[09-16 20:14] - Train loss: 3.2903 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:14] - Val   loss: 8.3659 | Acc_@1: 0.9666 | mAP@10: 0.9654 | .5Acc+.5mAP: 0.9660 | CMC@10: 0.9928
[09-16 20:14] - Epoch 21: best loss improved from 9.1513 to 8.3659
[09-16 20:14] - Epoch 22 | lr 3.13e-02
[09-16 20:22] - Train loss: 2.9747 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:22] - Val   loss: 8.1169 | Acc_@1: 0.9693 | mAP@10: 0.9679 | .5Acc+.5mAP: 0.9686 | CMC@10: 0.9923
[09-16 20:22] - Epoch 22: best loss improved from 8.3659 to 8.1169
[09-16 20:22] - Epoch 23 | lr 2.98e-02
[09-16 20:29] - Train loss: 2.7703 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:29] - Val   loss: 8.0507 | Acc_@1: 0.9719 | mAP@10: 0.9695 | .5Acc+.5mAP: 0.9707 | CMC@10: 0.9930
[09-16 20:29] - Epoch 23: best loss improved from 8.1169 to 8.0507
[09-16 20:29] - Epoch 24 | lr 2.83e-02
[09-16 20:37] - Train loss: 2.5650 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:37] - Val   loss: 8.0343 | Acc_@1: 0.9717 | mAP@10: 0.9696 | .5Acc+.5mAP: 0.9706 | CMC@10: 0.9928
[09-16 20:37] - Epoch 24: best loss improved from 8.0507 to 8.0343
[09-16 20:37] - Epoch 25 | lr 2.67e-02
[09-16 20:44] - Train loss: 2.3161 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:44] - Val   loss: 7.7895 | Acc_@1: 0.9736 | mAP@10: 0.9726 | .5Acc+.5mAP: 0.9731 | CMC@10: 0.9933
[09-16 20:44] - Epoch 25: best loss improved from 8.0343 to 7.7895
[09-16 20:44] - Epoch 26 | lr 2.51e-02
[09-16 20:51] - Train loss: 2.1940 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:51] - Val   loss: 7.4411 | Acc_@1: 0.9721 | mAP@10: 0.9726 | .5Acc+.5mAP: 0.9723 | CMC@10: 0.9933
[09-16 20:51] - Epoch 26: best loss improved from 7.7895 to 7.4411
[09-16 20:51] - Epoch 27 | lr 2.36e-02
[09-16 20:59] - Train loss: 2.0122 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 20:59] - Val   loss: 7.5599 | Acc_@1: 0.9736 | mAP@10: 0.9735 | .5Acc+.5mAP: 0.9735 | CMC@10: 0.9935
[09-16 20:59] - Epoch 28 | lr 2.20e-02
[09-16 21:06] - Train loss: 1.8820 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:06] - Val   loss: 7.2695 | Acc_@1: 0.9777 | mAP@10: 0.9762 | .5Acc+.5mAP: 0.9769 | CMC@10: 0.9952
[09-16 21:06] - Epoch 28: best loss improved from 7.4411 to 7.2695
[09-16 21:06] - Epoch 29 | lr 2.04e-02
[09-16 21:14] - Train loss: 1.7089 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:14] - Val   loss: 6.9934 | Acc_@1: 0.9793 | mAP@10: 0.9766 | .5Acc+.5mAP: 0.9780 | CMC@10: 0.9947
[09-16 21:14] - Epoch 29: best loss improved from 7.2695 to 6.9934
[09-16 21:14] - Epoch 30 | lr 1.89e-02
[09-16 21:22] - Train loss: 1.6501 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:22] - Val   loss: 6.9398 | Acc_@1: 0.9803 | mAP@10: 0.9784 | .5Acc+.5mAP: 0.9793 | CMC@10: 0.9947
[09-16 21:22] - Epoch 30: best loss improved from 6.9934 to 6.9398
[09-16 21:22] - Epoch 31 | lr 1.74e-02
[09-16 21:30] - Train loss: 1.5214 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:30] - Val   loss: 6.8700 | Acc_@1: 0.9765 | mAP@10: 0.9757 | .5Acc+.5mAP: 0.9761 | CMC@10: 0.9940
[09-16 21:30] - Epoch 31: best loss improved from 6.9398 to 6.8700
[09-16 21:30] - Epoch 32 | lr 1.59e-02
[09-16 21:37] - Train loss: 1.4544 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:37] - Val   loss: 6.3306 | Acc_@1: 0.9837 | mAP@10: 0.9813 | .5Acc+.5mAP: 0.9825 | CMC@10: 0.9952
[09-16 21:37] - Epoch 32: best loss improved from 6.8700 to 6.3306
[09-16 21:37] - Epoch 33 | lr 1.45e-02
[09-16 21:45] - Train loss: 1.3725 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:45] - Val   loss: 6.2972 | Acc_@1: 0.9827 | mAP@10: 0.9806 | .5Acc+.5mAP: 0.9816 | CMC@10: 0.9947
[09-16 21:45] - Epoch 33: best loss improved from 6.3306 to 6.2972
[09-16 21:45] - Epoch 34 | lr 1.31e-02
[09-16 21:53] - Train loss: 1.2991 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 21:53] - Val   loss: 6.4566 | Acc_@1: 0.9810 | mAP@10: 0.9805 | .5Acc+.5mAP: 0.9808 | CMC@10: 0.9957
[09-16 21:53] - Epoch 35 | lr 1.17e-02
[09-16 22:00] - Train loss: 1.2791 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:00] - Val   loss: 6.3949 | Acc_@1: 0.9820 | mAP@10: 0.9808 | .5Acc+.5mAP: 0.9814 | CMC@10: 0.9966
[09-16 22:00] - Epoch 36 | lr 1.04e-02
[09-16 22:08] - Train loss: 1.2279 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:08] - Val   loss: 6.2251 | Acc_@1: 0.9841 | mAP@10: 0.9825 | .5Acc+.5mAP: 0.9833 | CMC@10: 0.9957
[09-16 22:08] - Epoch 36: best loss improved from 6.2972 to 6.2251
[09-16 22:08] - Epoch 37 | lr 9.16e-03
[09-16 22:16] - Train loss: 1.1886 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:16] - Val   loss: 6.1530 | Acc_@1: 0.9849 | mAP@10: 0.9824 | .5Acc+.5mAP: 0.9836 | CMC@10: 0.9964
[09-16 22:16] - Epoch 37: best loss improved from 6.2251 to 6.1530
[09-16 22:16] - Epoch 38 | lr 7.98e-03
[09-16 22:23] - Train loss: 1.1544 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:23] - Val   loss: 5.9900 | Acc_@1: 0.9858 | mAP@10: 0.9827 | .5Acc+.5mAP: 0.9843 | CMC@10: 0.9966
[09-16 22:23] - Epoch 38: best loss improved from 6.1530 to 5.9900
[09-16 22:23] - Epoch 39 | lr 6.86e-03
[09-16 22:31] - Train loss: 1.1504 | Acc_@1: 0.0000 | mAP@10: 0.0000 | .5Acc+.5mAP: 0.0000 | CMC@10: 0.0000
[09-16 22:31] - Val   loss: 6.1023 | Acc_@1: 0.9846 | mAP@10: 0.9826 | .5Acc+.5mAP: 0.9836 | CMC@10: 0.9971
[09-16 22:31] - Epoch 40 | lr 5.82e-03
