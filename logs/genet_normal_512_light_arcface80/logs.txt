[09-19 23:46] - Parameters used for training: Namespace(arch='genet_normal', augmentation='light', batch_size=64, config_file='configs/1_genet_normal_512.yaml', criterion='arcface', criterion_params={'out_features': 3097, 's': 80.0, 'm': 1.0}, debug=False, ema_decay=0.0, embedding_size=512, freeze_bn=False, model_params={}, name='genet_normal_512_light_arcface80', optim='adamw', outdir='logs/genet_normal_512_light_arcface80', phases=[{'ep': [0, 30], 'lr': [0.01, 0.0001]}], pooling='gem', resume='', root='data/interim', seed=42, size=512, tta=False, use_fp16=True, val_frequency=1, val_size=768, weight_decay=1e-05, workers=8)
[09-19 23:46] - Model size: 19.89M
[09-19 23:46] - Loss for this run is: AdditiveAngularMarginLoss(
  (criterion): CrossEntropyLoss()
)
[09-19 23:46] - Using sizes {(680, 512), (512, 512), (1024, 512), (512, 904), (512, 640), (640, 512), (512, 768), (904, 512), (512, 680), (512, 1024), (768, 512)} for train
[09-19 23:46] - Using sizes {(768, 1360), (960, 768), (1536, 768), (768, 768), (1360, 768), (1152, 768), (768, 1536), (1024, 768), (768, 960), (768, 1024), (768, 1152)} for validation
[09-19 23:46] - Val size: 16672
[09-19 23:46] - Train size: 51935
[09-19 23:46] - Start training
[09-19 23:46] - Start phase #1 from epoch 0 to epoch 30: {'ep': [0, 30], 'lr': [0.01, 0.0001], 'mom': [], 'mode': 'linear'}
[09-19 23:46] - Epoch 1 | lr 0.00e+00
[09-19 23:52] - TimeMeter profiling. Data time: 5.87E-04s. Model time: 3.91E-01s 

