{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:11:02.480549Z",
     "start_time": "2020-09-16T18:11:00.920807Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:11:05.026507Z",
     "start_time": "2020-09-16T18:11:05.000072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "# Fix to be able to import python modules inside a notebook\n",
    "os.chdir('..')\n",
    "\n",
    "# Useful extensions\n",
    "# %load_ext watermark\n",
    "# %watermark -v -n -m -p numpy,torch,albumentations,photosynthesis_metrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Nice plot formating\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:19:57.141871Z",
     "start_time": "2020-09-16T18:19:56.507590Z"
    }
   },
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from src.callbacks import cmc_score_count, rank_map_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:20:06.358308Z",
     "start_time": "2020-09-16T18:20:00.854793Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = pathlib.Path(\"logs/resnet101_384_arcface_fp16_gem_light/\")\n",
    "# Val: Acc@1 0.81258, CMC@10 0.92955, mAP@10 0.80109, target 0.80683. In reality it's 0.56\n",
    "CONFIG_PATH = pathlib.Path(\"logs/genet_normal_384_arcface_fp16_gem_light/\") \n",
    "df = pd.read_csv(CONFIG_PATH / \"train_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:23:51.954109Z",
     "start_time": "2020-09-16T18:23:07.495205Z"
    }
   },
   "outputs": [],
   "source": [
    "val_embeddings = torch.tensor(list(map(eval, df[\"embeddings\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:53:39.548626Z",
     "start_time": "2020-09-16T18:53:34.197457Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "topk_vals, topk_ind = distances.neg().topk(top_k, dim=1)\n",
    "cosine_dist = (2 - topk_vals.neg()) * 0.5 # cos = ((2 - l2_distances) / 2)\n",
    "cosine_weight = (cosine_dist ** alpha)[..., None] # N x TOPK -> N x TOPK x 1\n",
    "# new_embedding = val_embeddings[topk_ind].mean(dim=1)\n",
    "(val_embeddings[topk_ind] * cosine_weight).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T18:21:20.099908Z",
     "start_time": "2020-09-16T18:21:20.074293Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_based_augmentation(embeddings, top_k=10, alpha=2, include_self=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        embeddings (Tensor): original embeddings\n",
    "        top_k (int): How many neighbours to use\n",
    "        alpha (int): Power for \n",
    "    \"\"\"\n",
    "    # Matrix of pairwise cosin distances\n",
    "    distances = torch.cdist(val_embeddings, val_embeddings)\n",
    "    # Nearest neighbours\n",
    "    topk_vals, topk_ind = distances.neg().topk(top_k, dim=1)\n",
    "    # Get weight\n",
    "    cosine_dist = (2 - topk_vals.neg()) * 0.5 # cos = ((2 - l2_distances) / 2)\n",
    "    cosine_weight = (cosine_dist ** alpha)[..., None] # N x TOPK -> N x TOPK x 1\n",
    "    new_embedding = val_embeddings[topk_ind] * cosine_weight # N x TOPK x EMBED_SIZE * N x TOPK x 1\n",
    "    if include_self:\n",
    "        new_embedding = new_embedding.mean(dim=1)\n",
    "    else:\n",
    "        new_embedding = new_embedding[:, 1:].mean(dim=1)\n",
    "    return new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
